<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>Random Sampling</title>
  <link rel="stylesheet" type="text/css" href="/assets/main.css">
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
<header>
  <div class="menu">
    <h1><a href="/">turtleblog</a></h1>
    <ul><li><a href="/about/">/about</a></li></ul>
  </div>
</header>
<main>
      <h1>Random Sampling</h1>
<p>Apr 17, 2013</p>
<p></p>

<p>Given a set of items, choosing random one with equal probability can be done by <code class="language-plaintext highlighter-rouge">random.choice(items)</code>.
But what if we are given items one by one without knowing the length of the whole set?</p>

<p>There is a simple algorithm: For the $k$-th item, we give up previous selection and choose this one with probability $\frac 1 k$.
Proof as follows: If we select the $k$-th item, it means that we choose it with probability $\frac 1 k$ and give up all successors. 
Product of probabilities of all these choices is:</p>

<p>$$ p_k = \frac 1 k \times \frac {k} {k+1} \times \cdots \times \frac {n-2}{n-1} \times \frac {n-1} n = \frac 1 n $$</p>

<p>Codes in Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">choice</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>
    <span class="n">selection</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">selection</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">return</span> <span class="n">selection</span>
</code></pre></div></div>

<p>We can generalize this algorithm. For a set of items, each one is associated with a weight $w_i$.
Our goal is to select a random one based on its weight ratio.
The algorithm is similar to the previous one: For the $k$-th item, replace the current selection with it with probability $\frac {w_k} {\sum_{i=1}^k w_i}$.
Proof is analogical:</p>

<p>$$p_k = \frac {w_k} {\sum_{i=1}^k w_i} \times \frac {\sum_{i=1}^k w_i} {\sum_{i=1}^{k+1} w_i} 
\times \cdots \times \frac {\sum_{i=1}^{n-2} w_i} {\sum_{i=1}^{n-1} w_i} \times \frac {\sum_{i=1}^{n-1} w_i} {\sum_{i=1}^{n} w_i} = \frac {w_k} {\sum_{i=1}^n w_i}$$</p>

<p>Codes in Python:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weightedChoice</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">selection</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">total_weight</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">item</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="n">total_weight</span> <span class="o">+=</span> <span class="n">weight</span>
        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">*</span> <span class="n">total_weight</span> <span class="o">&lt;</span> <span class="n">weight</span><span class="p">:</span>
            <span class="n">selection</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">return</span> <span class="n">selection</span>
</code></pre></div></div>

<p>There is another amazing method to do this weighted random sampling:
For each item, get a random $r_i \in [0, 1]$,
and <em>reweight</em> this item as $w’_i = r_i^{1 / {w_i}}$.
Then we can select the one with the top new weight. Proof of this is a bit annoying.</p>

<p>If we choose the $i$-th item at last, this means $\forall j\neq i, w’_j &lt;w’_i$. As $r_i \in [0, 1]$, the probability is:</p>

<p>$$ p_i = \int_0^1 p(\forall j\neq i, w’_j &lt;w’_i)\ \mathrm{d}\ r_i $$</p>

<p>$r_j$ is independent with each other. So:</p>

<p>$$ p_i = \int_0^1 \prod_{j \neq i} p(w’_j &lt;w’_i)\ \mathrm{d} \ r_i $$</p>

<p>As $r_j \in [0, 1]$, the inner probability can be simplified as:</p>

<p>$$ p(w’_j &lt;w’_i) = p(r_j^{1 / w_j} &lt; r_i^{1 / w_i}) = p(r_j &lt; r_i^{w_j / w_i}) = r_i^{w_j / w_i} $$</p>

<p>So:</p>

<p>$$ p_i = \int_0^1 \prod_{j \neq i} r_i^{w_j / w_i}\ \mathrm{d}\ r_i
= \int_0^1 r_i^{(w-w_i) / w_i}\ \mathrm{d}\ r_i = \frac {w_i} w $$</p>

<p>Same as our expectation.</p>

<p>This blog is basically a summary of
<a href="http://www.gocalf.com/blog/random-selection.html">these</a>
<a href="http://www.gocalf.com/blog/weighted-random-selection.html">three</a>
<a href="http://www.gocalf.com/blog/weighted-random-selection-2.html">blogs</a>.
Refer to them for more content.</p>


    </main><footer>
   <a href="https://github.com/scturtle"><svg><use xlink:href="/assets/icons.svg#github"></use></svg></a>
   <a href="https://twitter.com/scturtle"><svg><use xlink:href="/assets/icons.svg#twitter"></use></svg></a>
   <a href="https://t.me/scturtle"><svg><use xlink:href="/assets/icons.svg#telegram"></use></svg></a>
   <a href="/feed.xml"><svg><use xlink:href="/assets/icons.svg#rss"></use></svg></a>
</footer>
</div>
  </body>
</html>
